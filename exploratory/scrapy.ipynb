{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import random\n",
    "import urllib.request\n",
    "import ssl\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://brd.superproxy.io:33335\n",
      "brd-customer-hl_51e27139-zone-residential_proxy1\n",
      "dbgb6ojk1bp8\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "BRD_PROXY_USERNAME = os.getenv(\"BRD_PROXY_USERNAME\")\n",
    "BRD_SERVER = os.getenv(\"BRD_SERVER\").replace(\"https://\", \"\")\n",
    "BRD_PROXY_PASSWORD = os.getenv(\"BRD_PROXY_PASSWORD\")\n",
    "proxy = f\"http://{BRD_PROXY_USERNAME}:{BRD_PROXY_PASSWORD}@{BRD_SERVER}\"\n",
    "\n",
    "MIN_DELAY_SECONDS = 5\n",
    "MAX_DELAY_SECONDS = 15\n",
    "NUM_URLS_TO_SCRAPE = 10\n",
    "\n",
    "print(BRD_SERVER)\n",
    "print(BRD_PROXY_USERNAME)\n",
    "print(BRD_PROXY_PASSWORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_user_agent():\n",
    "    \"\"\"\n",
    "    Generate a random plausible Chrome-based user agent string.\n",
    "    \"\"\"\n",
    "    # OS options\n",
    "    os_options = [\n",
    "        \"Windows NT 10.0; Win64; x64\",\n",
    "        \"Windows NT 10.0; WOW64\",\n",
    "        \"Windows NT 6.1; Win64; x64\",\n",
    "        \"Macintosh; Intel Mac OS X 10_15_7\",\n",
    "        \"Macintosh; Intel Mac OS X 11_2_3\",\n",
    "        \"X11; Linux x86_64\",\n",
    "    ]\n",
    "    os_str = random.choice(os_options)\n",
    "\n",
    "    # Chrome version\n",
    "    chrome_major = random.randint(90, 120)\n",
    "    chrome_minor = random.randint(0, 0)\n",
    "    chrome_build = random.randint(4400, 5800)\n",
    "    chrome_patch = random.randint(50, 200)\n",
    "    chrome_version = f\"{chrome_major}.0.{chrome_build}.{chrome_patch}\"\n",
    "\n",
    "    # AppleWebKit version\n",
    "    webkit_major = 537\n",
    "    webkit_minor = random.randint(36, 50)\n",
    "    webkit_version = f\"{webkit_major}.{webkit_minor}\"\n",
    "\n",
    "    # Safari version\n",
    "    safari_major = 537\n",
    "    safari_minor = random.randint(36, 50)\n",
    "    safari_version = f\"{safari_major}.{safari_minor}\"\n",
    "\n",
    "    user_agent = (\n",
    "        f\"Mozilla/5.0 ({os_str}) \"\n",
    "        f\"AppleWebKit/{webkit_version} (KHTML, like Gecko) \"\n",
    "        f\"Chrome/{chrome_version} Safari/{safari_version}\"\n",
    "    )\n",
    "    return user_agent\n",
    "\n",
    "\n",
    "def generate_random_accept_language():\n",
    "    # Common Accept-Language header values\n",
    "    languages = [\n",
    "        \"en-US,en;q=0.9\",\n",
    "        \"en-GB,en;q=0.8\",\n",
    "        \"en-US,en;q=0.8,fr;q=0.6\",\n",
    "        \"en-US,en;q=0.7,es;q=0.3\",\n",
    "        \"en-US,en;q=0.9,fr-CA;q=0.7,fr;q=0.6\",\n",
    "        \"en-US,en;q=0.9,es-ES;q=0.7,es;q=0.6\",\n",
    "    ]\n",
    "    return random.choice(languages)\n",
    "\n",
    "\n",
    "def generate_random_accept_encoding():\n",
    "    # Common Accept-Encoding header values\n",
    "    encodings = [\n",
    "        \"gzip, deflate, br\",\n",
    "        \"gzip, deflate\",\n",
    "        \"br, gzip, deflate\",\n",
    "        \"gzip\",\n",
    "    ]\n",
    "    return random.choice(encodings)\n",
    "\n",
    "\n",
    "def generate_random_accept():\n",
    "    # Common Accept header values\n",
    "    accepts = [\n",
    "        \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "        \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"text/html,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    ]\n",
    "    return random.choice(accepts)\n",
    "\n",
    "\n",
    "def generate_random_referer(url):\n",
    "    # If the URL looks like a property page, set referer to a plausible search page\n",
    "    # Otherwise, use a generic referer\n",
    "    if \"streeteasy.com\" in url:\n",
    "        # Try to extract the neighborhood from the URL\n",
    "        import re\n",
    "\n",
    "        m = re.search(r\"/for-rent/([^/]+)\", url)\n",
    "        if m:\n",
    "            neighborhood = m.group(1)\n",
    "            referer = f\"https://streeteasy.com/for-rent/{neighborhood}?sort_by=se_score\"\n",
    "        else:\n",
    "            referer = \"https://streeteasy.com/for-rent/nyc\"\n",
    "    else:\n",
    "        referer = \"https://www.google.com/\"\n",
    "    return referer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_headers(url=None):\n",
    "    headers = {\n",
    "        \"User-Agent\": generate_random_user_agent(),\n",
    "        # \"Accept-Language\": generate_random_accept_language(),\n",
    "        # \"Accept-Encoding\": generate_random_accept_encoding(),\n",
    "        # \"Accept\": generate_random_accept(),\n",
    "    }\n",
    "    if url:\n",
    "        headers[\"Referer\"] = generate_random_referer(url)\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit_url_with_proxy(url, proxy, headers=None):\n",
    "    \"\"\"\n",
    "    Visit a URL using the specified proxy and optional headers.\n",
    "    Returns the response content as a string.\n",
    "    \"\"\"\n",
    "    if headers is None:\n",
    "        headers = generate_random_headers(url)\n",
    "    req = urllib.request.Request(url, headers=headers)\n",
    "    opener = urllib.request.build_opener(\n",
    "        urllib.request.ProxyHandler({\"https\": proxy, \"http\": proxy}),\n",
    "        # NOTE: Using _create_unverified_context bypasses SSL cert checks, be cautious.\n",
    "        urllib.request.HTTPSHandler(context=ssl._create_unverified_context()),\n",
    "    )\n",
    "    try:\n",
    "        with opener.open(req) as response:\n",
    "            return response.read().decode()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_range = [2000, 5000]\n",
    "beds = [0, 1, 2, 3, 4]\n",
    "neighborhoods = [\n",
    "    \"battery-park-city\",\n",
    "    \"financial-district\",\n",
    "    \"greenwich-village\",\n",
    "    \"soho\",\n",
    "    \"tribeca\",\n",
    "    \"east-village\",\n",
    "    \"west-village\",\n",
    "    \"chelsea\",\n",
    "    \"flatiron\",\n",
    "    \"gramercy\",\n",
    "    \"hudson-square\",\n",
    "    \"noho\",\n",
    "    \"nolita\",\n",
    "    \"soho\",\n",
    "    \"tribeca\",\n",
    "    \"west-village\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streeteasy_url(\n",
    "    price_range: tuple[int, int], beds: list[int], neighborhoods: list[str]\n",
    "):\n",
    "    url = f\"https://streeteasy.com/for-rent/{neighborhoods}/price:{price_range[0]}-{price_range[1]}|beds:{beds}?sort_by=se_score\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_streeteasy_url(\n",
    "    price_range: tuple[int, int], beds: list[int], neighborhoods: list[str]\n",
    "):\n",
    "    neighborhood = random.choice(neighborhoods)\n",
    "    min_price = random.randint(price_range[0], price_range[1])\n",
    "    max_price = random.randint(min_price, price_range[1])\n",
    "\n",
    "    # HACK: Round prices to the nearest $50 to look more human\n",
    "    min_price = round(min_price / 50) * 50\n",
    "    max_price = round(max_price / 50) * 50\n",
    "\n",
    "    beds = random.choice(beds)\n",
    "    url = f\"https://streeteasy.com/for-rent/{neighborhood}/price:{min_price}-{max_price}|beds:{beds}?sort_by=se_score\"\n",
    "    print(url)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://streeteasy.com/for-rent/battery-park-city/price:2750-3100|beds:0?sort_by=se_score\n",
      "Error: HTTP Error 403: Forbidden\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "url = get_random_streeteasy_url(price_range, beds, neighborhoods)\n",
    "result = visit_url_with_proxy(url, proxy)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_single_url(price_range, beds, neighborhoods, proxy):\n",
    "    # Introduce a random delay before making the request\n",
    "    delay = random.uniform(MIN_DELAY_SECONDS, MAX_DELAY_SECONDS)\n",
    "    print(f\"Sleeping for {delay:.2f} seconds before scraping...\")\n",
    "    time.sleep(delay)\n",
    "    url = get_random_streeteasy_url(price_range, beds, neighborhoods)\n",
    "    result = visit_url_with_proxy(url, proxy)\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def scrape_random_urls(n, price_range, beds, neighborhoods, proxy):\n",
    "    return [\n",
    "        scrape_single_url(price_range, beds, neighborhoods, proxy) for _ in range(n)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def a_scrape_single_url(price_range, beds, neighborhoods, proxy):\n",
    "    # Introduce a random delay before making the request\n",
    "    delay = random.uniform(MIN_DELAY_SECONDS, MAX_DELAY_SECONDS)\n",
    "    print(f\"Sleeping for {delay:.2f} seconds before scraping...\")\n",
    "    await asyncio.sleep(delay)\n",
    "    url = get_random_streeteasy_url(price_range, beds, neighborhoods)\n",
    "    result = visit_url_with_proxy(url, proxy)\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def a_scrape_random_urls_parallel(n, price_range, beds, neighborhoods, proxy):\n",
    "    async def run_parallel():\n",
    "        tasks = [\n",
    "            a_scrape_single_url(price_range, beds, neighborhoods, proxy)\n",
    "            for _ in range(n)\n",
    "        ]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results\n",
    "\n",
    "    return asyncio.run(run_parallel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price of Request Scraping vs. Headless Browser Scraping\n",
    "Prices are much lower for request scraping, but the quality of the data is lower since images are not scraped.\n",
    "This means a much greater volume of text data can be requested holding price constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping for 10.87 seconds before scraping...\n",
      "https://streeteasy.com/for-rent/financial-district/price:4000-4500|beds:4?sort_by=se_score\n",
      "Error: HTTP Error 403: Forbidden\n",
      "None\n",
      "Sleeping for 8.29 seconds before scraping...\n",
      "https://streeteasy.com/for-rent/hudson-square/price:4800-4850|beds:4?sort_by=se_score\n",
      "Error: HTTP Error 403: Forbidden\n",
      "None\n",
      "Sleeping for 7.91 seconds before scraping...\n",
      "https://streeteasy.com/for-rent/east-village/price:3900-4800|beds:2?sort_by=se_score\n",
      "Error: HTTP Error 403: Forbidden\n",
      "None\n",
      "Sleeping for 5.91 seconds before scraping...\n",
      "https://streeteasy.com/for-rent/noho/price:2850-3700|beds:0?sort_by=se_score\n",
      "Error: HTTP Error 403: Forbidden\n",
      "None\n",
      "Sleeping for 6.46 seconds before scraping...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mscrape_random_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNUM_URLS_TO_SCRAPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprice_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighborhoods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mscrape_random_urls\u001b[39m\u001b[34m(n, price_range, beds, neighborhoods, proxy)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscrape_random_urls\u001b[39m(n, price_range, beds, neighborhoods, proxy):\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[43mscrape_single_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprice_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighborhoods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n)\n\u001b[32m     15\u001b[39m     ]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mscrape_single_url\u001b[39m\u001b[34m(price_range, beds, neighborhoods, proxy)\u001b[39m\n\u001b[32m      3\u001b[39m delay = random.uniform(MIN_DELAY_SECONDS, MAX_DELAY_SECONDS)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSleeping for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds before scraping...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m url = get_random_streeteasy_url(price_range, beds, neighborhoods)\n\u001b[32m      7\u001b[39m result = visit_url_with_proxy(url, proxy)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "scrape_random_urls(NUM_URLS_TO_SCRAPE, price_range, beds, neighborhoods, proxy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broker_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
